{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W = 114, 129\n",
    "\n",
    "ref_y, ref_x = torch.meshgrid(\n",
    "                torch.linspace(\n",
    "                    0.5, H - 0.5, H, dtype=torch.float32),\n",
    "                torch.linspace(\n",
    "                    0.5, W - 0.5, W, dtype=torch.float32))\n",
    "                    # 둘 다 (H=114, W=129)\n",
    "                    # [  0.5000,   1.5000,   2.5000,  ..., 126.5000, 127.5000, 128.5000] 이 114줄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.5000,   1.5000,   2.5000,  ..., 126.5000, 127.5000, 128.5000],\n",
       "        [  0.5000,   1.5000,   2.5000,  ..., 126.5000, 127.5000, 128.5000],\n",
       "        [  0.5000,   1.5000,   2.5000,  ..., 126.5000, 127.5000, 128.5000],\n",
       "        ...,\n",
       "        [  0.5000,   1.5000,   2.5000,  ..., 126.5000, 127.5000, 128.5000],\n",
       "        [  0.5000,   1.5000,   2.5000,  ..., 126.5000, 127.5000, 128.5000],\n",
       "        [  0.5000,   1.5000,   2.5000,  ..., 126.5000, 127.5000, 128.5000]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntensor([[[  0.5000,   0.5000],\\n         [  1.5000,   0.5000],\\n         [  2.5000,   0.5000],\\n         ...,\\n         [126.5000, 113.5000],\\n         [127.5000, 113.5000],\\n         [128.5000, 113.5000]]])\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_y = ref_y.reshape(-1)[None] #tensor([[  0.5000,   0.5000,   0.5000,  ..., 113.5000, 113.5000, 113.5000]]) -> torch.Size([1, 14706])\n",
    "ref_x = ref_x.reshape(-1)[None] #tensor([[  0.5000,   1.5000,   2.5000,  ..., 126.5000, 127.5000, 128.5000]]) -> torch.Size([1, 14706])\n",
    "ref = torch.stack((ref_x, ref_y), -1) # torch.Size([1, 14706, 2])\n",
    "\"\"\"\n",
    "tensor([[[  0.5000,   0.5000],\n",
    "         [  1.5000,   0.5000],\n",
    "         [  2.5000,   0.5000],\n",
    "         ...,\n",
    "         [126.5000, 113.5000],\n",
    "         [127.5000, 113.5000],\n",
    "         [128.5000, 113.5000]]])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_list = []\n",
    "ref_list.append(ref)\n",
    "ref_list.append(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 29412, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_points = torch.cat(ref_list, 1)\n",
    "reference_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 29412, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "valid_ratios = torch.randint(1, 10, (2, 4, 2))\n",
    "print(reference_points[:, :, None].shape)\n",
    "reference_points = reference_points[:, :, None] * valid_ratios[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 29412, 1, 4, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_points[:, :, None].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "spatial_shapes = torch.Tensor([[114, 129], [57, 65], [29, 33], [15, 17]])\n",
    "print(spatial_shapes.shape)\n",
    "level_start_index = torch.cat((spatial_shapes.new_zeros((1, )), spatial_shapes.prod(1).cumsum(0)[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0., 14706., 18411., 19368.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_start_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dims = 256\n",
    "cls_out_channels = 2 # 1일 수도?\n",
    "num_pred = 4 # 디코더 레이어 개수 +1\n",
    "fc_cls = nn.Linear(embed_dims, cls_out_channels)\n",
    "cls_branches = nn.ModuleList([fc_cls for _ in range(num_pred)]) # len = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10000, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_proposals = torch.randint(0, 9, (2, 10000, 4)) #(bs, num_keys, 4)\n",
    "output_proposals[..., 1:2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs_class = torch.randint(0, 9, (3, 10000, 2)) #(bs, num_keys, cls_out_channels)\n",
    "topk_proposals = torch.topk(enc_outputs_class[..., 0], 300, dim=1)[0]\n",
    "enc_outputs_kpt_unact = torch.randint(0, 1, (3, 10000, 34)) #(bs, num_keys, 2*17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 300, 34])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_proposals.unsqueeze(-1).repeat(1, 1, 34).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "topk_kpts_unact = torch.gather(\n",
    "                enc_outputs_kpt_unact, 1,\n",
    "                topk_proposals.unsqueeze(-1).repeat(\n",
    "                    1, 1, enc_outputs_kpt_unact.size(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 300, 34])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_kpts_unact.sigmoid().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([300, 255]), torch.Size([300, 1]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_qurey = 300\n",
    "c = 256\n",
    "query_embed = torch.randint(0, 2, (num_qurey, c))\n",
    "query_pos, query = torch.split(query_embed, c, dim=1)\n",
    "query_pos.shape, query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 168, 320])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size, input_img_h, input_img_w = 2, 120, 240\n",
    "feat = torch.randint(0, 256, (168, 320), dtype=torch.float)\n",
    "img_masks = feat.new_ones((batch_size, input_img_h, input_img_w))\n",
    "mlvl_mask = F.interpolate(img_masks[None], size=feat.shape[-2:]).to(torch.bool).squeeze(0)\n",
    "mlvl_mask.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
